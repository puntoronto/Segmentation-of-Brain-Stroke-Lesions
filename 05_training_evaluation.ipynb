{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Eğitimi ve Değerlendirme\n",
    "\n",
    "Bu notebook, U-Net ve hibrit modellerin eğitimi, test edilmesi ve performans karşılaştırması için kodları içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Önceki notebook'lardan gerekli sınıfları import et\n",
    "# Gerçek uygulamada bu modüller ayrı dosyalarda olacak\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Kullanılan device: {device}\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitim Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                scheduler=None, num_epochs=50, device='cpu', model_name='model'):\n",
    "    \"\"\"\n",
    "    Model eğitimi fonksiyonu\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Eğitim geçmişi\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_dice': [],\n",
    "        'val_dice': [],\n",
    "        'learning_rate': []\n",
    "    }\n",
    "    \n",
    "    best_val_dice = 0.0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"Model eğitimi başlatılıyor: {model_name}\")\n",
    "    print(f\"Epochs: {num_epochs}, Device: {device}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Eğitim fazı\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for batch_idx, (images, masks) in enumerate(train_pbar):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Loss hesaplama\n",
    "            if hasattr(criterion, 'forward') and len(criterion.forward.__code__.co_varnames) > 2:\n",
    "                # Hybrid loss\n",
    "                loss, seg_loss, topo_loss = criterion(outputs, masks)\n",
    "            else:\n",
    "                # Standard loss\n",
    "                loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metrikleri hesapla\n",
    "            with torch.no_grad():\n",
    "                dice = compute_dice_score(outputs, masks)\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_dice += dice\n",
    "            \n",
    "            # Progress bar güncelle\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Dice': f'{dice:.4f}'\n",
    "            })\n",
    "        \n",
    "        # Validation fazı\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n",
    "            \n",
    "            for images, masks in val_pbar:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Loss hesaplama\n",
    "                if hasattr(criterion, 'forward') and len(criterion.forward.__code__.co_varnames) > 2:\n",
    "                    loss, _, _ = criterion(outputs, masks)\n",
    "                else:\n",
    "                    loss = criterion(outputs, masks)\n",
    "                \n",
    "                dice = compute_dice_score(outputs, masks)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_dice += dice\n",
    "                \n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Dice': f'{dice:.4f}'\n",
    "                })\n",
    "        \n",
    "        # Ortalama metrikleri hesapla\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_train_dice = train_dice / len(train_loader)\n",
    "        avg_val_dice = val_dice / len(val_loader)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(avg_val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # Geçmişe kaydet\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_dice'].append(avg_train_dice)\n",
    "        history['val_dice'].append(avg_val_dice)\n",
    "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # En iyi model kontrolü\n",
    "        if avg_val_dice > best_val_dice:\n",
    "            best_val_dice = avg_val_dice\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # En iyi modeli kaydet\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_dice': avg_val_dice,\n",
    "                'history': history\n",
    "            }, f'./model_outputs/checkpoints/best_{model_name}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Epoch özeti\n",
    "        print(f\"Epoch {epoch+1:3d}: Train Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Train Dice: {avg_train_dice:.4f}, \"\n",
    "              f\"Val Dice: {avg_val_dice:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Eğitim tamamlandı. En iyi validation Dice: {best_val_dice:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "def compute_dice_score(pred, target, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Dice skorunu hesapla\n",
    "    \"\"\"\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    intersection = (pred * target).sum()\n",
    "    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "    \n",
    "    return dice.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitim Geçmişi Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name='Model'):\n",
    "    \"\"\"\n",
    "    Eğitim geçmişini görselleştir\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', alpha=0.8)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation Loss', alpha=0.8)\n",
    "    axes[0, 0].set_title('Loss Curves')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dice curves\n",
    "    axes[0, 1].plot(history['train_dice'], label='Train Dice', alpha=0.8)\n",
    "    axes[0, 1].plot(history['val_dice'], label='Validation Dice', alpha=0.8)\n",
    "    axes[0, 1].set_title('Dice Score Curves')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Dice Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate\n",
    "    axes[1, 0].plot(history['learning_rate'], alpha=0.8, color='orange')\n",
    "    axes[1, 0].set_title('Learning Rate Schedule')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss vs Dice scatter\n",
    "    axes[1, 1].scatter(history['val_loss'], history['val_dice'], alpha=0.6, color='purple')\n",
    "    axes[1, 1].set_title('Validation Loss vs Dice Score')\n",
    "    axes[1, 1].set_xlabel('Validation Loss')\n",
    "    axes[1, 1].set_ylabel('Validation Dice Score')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'{model_name} Training History', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compare_training_histories(history1, history2, name1='Model 1', name2='Model 2'):\n",
    "    \"\"\"\n",
    "    İki modelin eğitim geçmişini karşılaştır\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Validation Loss karşılaştırması\n",
    "    axes[0].plot(history1['val_loss'], label=f'{name1} Val Loss', alpha=0.8)\n",
    "    axes[0].plot(history2['val_loss'], label=f'{name2} Val Loss', alpha=0.8)\n",
    "    axes[0].set_title('Validation Loss Comparison')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation Dice karşılaştırması\n",
    "    axes[1].plot(history1['val_dice'], label=f'{name1} Val Dice', alpha=0.8)\n",
    "    axes[1].plot(history2['val_dice'], label=f'{name2} Val Dice', alpha=0.8)\n",
    "    axes[1].set_title('Validation Dice Comparison')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Dice Score')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # İstatistikler\n",
    "    print(\"Eğitim İstatistikleri:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Metrik':<20} {name1:<15} {name2:<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'En İyi Val Dice':<20} {max(history1['val_dice']):<15.4f} {max(history2['val_dice']):<15.4f}\")\n",
    "    print(f\"{'En Düşük Val Loss':<20} {min(history1['val_loss']):<15.4f} {min(history2['val_loss']):<15.4f}\")\n",
    "    print(f\"{'Final Val Dice':<20} {history1['val_dice'][-1]:<15.4f} {history2['val_dice'][-1]:<15.4f}\")\n",
    "    print(f\"{'Final Val Loss':<20} {history1['val_loss'][-1]:<15.4f} {history2['val_loss'][-1]:<15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ve Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, model_name='Model'):\n",
    "    \"\"\"\n",
    "    Modeli test seti üzerinde değerlendir\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_dice = []\n",
    "    all_iou = []\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_f1 = []\n",
    "    \n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    images = []\n",
    "    \n",
    "    print(f\"Model değerlendiriliyor: {model_name}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, masks) in enumerate(tqdm(test_loader, desc='Evaluating')):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Batch içindeki her örnek için metrikleri hesapla\n",
    "            for i in range(imgs.shape[0]):\n",
    "                pred = probs[i, 0].cpu().numpy()\n",
    "                gt = masks[i, 0].cpu().numpy()\n",
    "                img = imgs[i, 0].cpu().numpy()\n",
    "                \n",
    "                # Binary tahmin\n",
    "                pred_binary = (pred > 0.5).astype(np.float32)\n",
    "                \n",
    "                # Metrikleri hesapla\n",
    "                dice = compute_dice_numpy(pred_binary, gt)\n",
    "                iou = compute_iou_numpy(pred_binary, gt)\n",
    "                precision, recall, f1 = compute_precision_recall_f1(pred_binary, gt)\n",
    "                \n",
    "                all_dice.append(dice)\n",
    "                all_iou.append(iou)\n",
    "                all_precision.append(precision)\n",
    "                all_recall.append(recall)\n",
    "                all_f1.append(f1)\n",
    "                \n",
    "                # İlk birkaç örneği kaydet (görselleştirme için)\n",
    "                if batch_idx < 3:\n",
    "                    predictions.append(pred)\n",
    "                    ground_truths.append(gt)\n",
    "                    images.append(img)\n",
    "    \n",
    "    # Ortalama metrikleri hesapla\n",
    "    results = {\n",
    "        'dice': np.mean(all_dice),\n",
    "        'iou': np.mean(all_iou),\n",
    "        'precision': np.mean(all_precision),\n",
    "        'recall': np.mean(all_recall),\n",
    "        'f1': np.mean(all_f1),\n",
    "        'dice_std': np.std(all_dice),\n",
    "        'iou_std': np.std(all_iou)\n",
    "    }\n",
    "    \n",
    "    # Sonuçları yazdır\n",
    "    print(f\"\\n{model_name} Test Sonuçları:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Dice Score: {results['dice']:.4f} ± {results['dice_std']:.4f}\")\n",
    "    print(f\"IoU Score: {results['iou']:.4f} ± {results['iou_std']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {results['f1']:.4f}\")\n",
    "    \n",
    "    return results, predictions, ground_truths, images\n",
    "\n",
    "def compute_dice_numpy(pred, target, smooth=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "    return dice\n",
    "\n",
    "def compute_iou_numpy(pred, target, smooth=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou\n",
    "\n",
    "def compute_precision_recall_f1(pred, target):\n",
    "    tp = (pred * target).sum()\n",
    "    fp = (pred * (1 - target)).sum()\n",
    "    fn = ((1 - pred) * target).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonuç Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(images, ground_truths, predictions, model_name='Model', num_samples=6):\n",
    "    \"\"\"\n",
    "    Model tahminlerini görselleştir\n",
    "    \"\"\"\n",
    "    num_samples = min(num_samples, len(images))\n",
    "    \n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(4*num_samples, 12))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Orijinal görüntü\n",
    "        axes[0, i].imshow(images[i], cmap='gray')\n",
    "        axes[0, i].set_title(f'Örnek {i+1} - Orijinal')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        axes[1, i].imshow(ground_truths[i], cmap='hot')\n",
    "        axes[1, i].set_title('Ground Truth')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Tahmin\n",
    "        axes[2, i].imshow(predictions[i], cmap='hot')\n",
    "        dice = compute_dice_numpy((predictions[i] > 0.5).astype(np.float32), ground_truths[i])\n",
    "        axes[2, i].set_title(f'{model_name}\\nDice: {dice:.3f}')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compare_model_predictions(images, ground_truths, pred1, pred2, \n",
    "                            name1='Model 1', name2='Model 2', num_samples=4):\n",
    "    \"\"\"\n",
    "    İki modelin tahminlerini karşılaştır\n",
    "    \"\"\"\n",
    "    num_samples = min(num_samples, len(images))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, num_samples, figsize=(4*num_samples, 16))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Orijinal görüntü\n",
    "        axes[0, i].imshow(images[i], cmap='gray')\n",
    "        axes[0, i].set_title(f'Örnek {i+1} - Orijinal')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        axes[1, i].imshow(ground_truths[i], cmap='hot')\n",
    "        axes[1, i].set_title('Ground Truth')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Model 1 tahmin\n",
    "        dice1 = compute_dice_numpy((pred1[i] > 0.5).astype(np.float32), ground_truths[i])\n",
    "        axes[2, i].imshow(pred1[i], cmap='hot')\n",
    "        axes[2, i].set_title(f'{name1}\\nDice: {dice1:.3f}')\n",
    "        axes[2, i].axis('off')\n",
    "        \n",
    "        # Model 2 tahmin\n",
    "        dice2 = compute_dice_numpy((pred2[i] > 0.5).astype(np.float32), ground_truths[i])\n",
    "        axes[3, i].imshow(pred2[i], cmap='hot')\n",
    "        axes[3, i].set_title(f'{name2}\\nDice: {dice2:.3f}')\n",
    "        axes[3, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_performance_comparison(results1, results2, name1='Model 1', name2='Model 2'):\n",
    "    \"\"\"\n",
    "    Model performanslarını karşılaştırmalı grafik\n",
    "    \"\"\"\n",
    "    metrics = ['dice', 'iou', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    values1 = [results1[m] for m in metrics]\n",
    "    values2 = [results2[m] for m in metrics]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, values1, width, label=name1, alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, values2, width, label=name2, alpha=0.8)\n",
    "    \n",
    "    # Değerleri çubukların üzerine yaz\n",
    "    for bar, value in zip(bars1, values1):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    for bar, value in zip(bars2, values2):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    ax.set_xlabel('Metrikler')\n",
    "    ax.set_ylabel('Skor')\n",
    "    ax.set_title('Model Performans Karşılaştırması')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([m.upper() for m in metrics])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # İyileştirme yüzdelerini hesapla\n",
    "    print(\"\\nPerformans İyileştirmeleri:\")\n",
    "    print(\"-\" * 40)\n",
    "    for metric in metrics:\n",
    "        improvement = ((results2[metric] - results1[metric]) / results1[metric]) * 100\n",
    "        symbol = \"↑\" if improvement > 0 else \"↓\" if improvement < 0 else \"=\"\n",
    "        print(f\"{metric.upper():<10}: {improvement:+6.2f}% {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ana Eğitim ve Değerlendirme Pipeline'ı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_training_pipeline():\n",
    "    \"\"\"\n",
    "    Ana eğitim ve değerlendirme pipeline'ı\n",
    "    \"\"\"\n",
    "    print(\"Beyin İnmesi Lezyon Segmentasyonu - Eğitim Pipeline'ı\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Veri yükleme (önceki notebook'tan)\n",
    "    print(\"1. Veri yükleniyor...\")\n",
    "    \n",
    "    # Gerçek uygulamada:\n",
    "    # from data_preprocessing import BrainStrokeDataset, get_augmentation_transforms\n",
    "    # from model_architectures import UNet, TopologyAwareUNet, HybridLoss, CombinedLoss\n",
    "    \n",
    "    # Örnek veri (gerçek veri yoksa)\n",
    "    # dataset = BrainStrokeDataset(...)\n",
    "    # train_size = int(0.7 * len(dataset))\n",
    "    # val_size = int(0.15 * len(dataset))\n",
    "    # test_size = len(dataset) - train_size - val_size\n",
    "    \n",
    "    # train_dataset, val_dataset, test_dataset = random_split(\n",
    "    #     dataset, [train_size, val_size, test_size]\n",
    "    # )\n",
    "    \n",
    "    print(\"Veri setleri hazırlandı.\")\n",
    "    \n",
    "    # 2. Model tanımlaması\n",
    "    print(\"\\n2. Modeller tanımlanıyor...\")\n",
    "    \n",
    "    # Standard U-Net\n",
    "    # unet_model = UNet(n_channels=1, n_classes=1)\n",
    "    \n",
    "    # Hibrit model\n",
    "    # hybrid_model = TopologyAwareUNet(n_channels=1, n_classes=1)\n",
    "    \n",
    "    print(\"Modeller tanımlandı.\")\n",
    "    \n",
    "    # 3. Eğitim parametreleri\n",
    "    print(\"\\n3. Eğitim parametreleri ayarlanıyor...\")\n",
    "    \n",
    "    # Optimizer ve scheduler\n",
    "    # unet_optimizer = optim.Adam(unet_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    # hybrid_optimizer = optim.Adam(hybrid_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    \n",
    "    # unet_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     unet_optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    # )\n",
    "    # hybrid_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     hybrid_optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    # )\n",
    "    \n",
    "    # Loss fonksiyonları\n",
    "    # unet_criterion = CombinedLoss(dice_weight=0.5, bce_weight=0.5)\n",
    "    # hybrid_criterion = HybridLoss(dice_weight=0.3, bce_weight=0.3, topo_weight=0.4)\n",
    "    \n",
    "    print(\"Eğitim parametreleri ayarlandı.\")\n",
    "    \n",
    "    # 4. Model eğitimi\n",
    "    print(\"\\n4. Model eğitimi başlatılıyor...\")\n",
    "    \n",
    "    # U-Net eğitimi\n",
    "    # print(\"U-Net eğitiliyor...\")\n",
    "    # unet_history = train_model(\n",
    "    #     unet_model, train_loader, val_loader, unet_criterion,\n",
    "    #     unet_optimizer, unet_scheduler, num_epochs=50,\n",
    "    #     device=device, model_name='unet'\n",
    "    # )\n",
    "    \n",
    "    # Hibrit model eğitimi\n",
    "    # print(\"\\nHibrit model eğitiliyor...\")\n",
    "    # hybrid_history = train_model(\n",
    "    #     hybrid_model, train_loader, val_loader, hybrid_criterion,\n",
    "    #     hybrid_optimizer, hybrid_scheduler, num_epochs=50,\n",
    "    #     device=device, model_name='hybrid'\n",
    "    # )\n",
    "    \n",
    "    print(\"Model eğitimleri tamamlandı.\")\n",
    "    \n",
    "    # 5. Eğitim geçmişi görselleştirme\n",
    "    print(\"\\n5. Eğitim geçmişi görselleştiriliyor...\")\n",
    "    \n",
    "    # plot_training_history(unet_history, 'Standard U-Net')\n",
    "    # plot_training_history(hybrid_history, 'Hibrit U-Net')\n",
    "    # compare_training_histories(unet_history, hybrid_history, 'U-Net', 'Hibrit')\n",
    "    \n",
    "    # 6. Test değerlendirmesi\n",
    "    print(\"\\n6. Test değerlendirmesi yapılıyor...\")\n",
    "    \n",
    "    # En iyi modelleri yükle\n",
    "    # unet_checkpoint = torch.load('./model_outputs/checkpoints/best_unet.pth')\n",
    "    # unet_model.load_state_dict(unet_checkpoint['model_state_dict'])\n",
    "    \n",
    "    # hybrid_checkpoint = torch.load('./model_outputs/checkpoints/best_hybrid.pth')\n",
    "    # hybrid_model.load_state_dict(hybrid_checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Test değerlendirmesi\n",
    "    # unet_results, unet_preds, gt, test_imgs = evaluate_model(\n",
    "    #     unet_model, test_loader, device, 'Standard U-Net'\n",
    "    # )\n",
    "    \n",
    "    # hybrid_results, hybrid_preds, _, _ = evaluate_model(\n",
    "    #     hybrid_model, test_loader, device, 'Hibrit U-Net'\n",
    "    # )\n",
    "    \n",
    "    # 7. Sonuç görselleştirme\n",
    "    print(\"\\n7. Sonuçlar görselleştiriliyor...\")\n",
    "    \n",
    "    # visualize_predictions(test_imgs, gt, unet_preds, 'Standard U-Net')\n",
    "    # visualize_predictions(test_imgs, gt, hybrid_preds, 'Hibrit U-Net')\n",
    "    # compare_model_predictions(test_imgs, gt, unet_preds, hybrid_preds, 'U-Net', 'Hibrit')\n",
    "    # plot_performance_comparison(unet_results, hybrid_results, 'Standard U-Net', 'Hibrit U-Net')\n",
    "    \n",
    "    # 8. Sonuçları kaydet\n",
    "    print(\"\\n8. Sonuçlar kaydediliyor...\")\n",
    "    \n",
    "    # results_summary = {\n",
    "    #     'unet_results': unet_results,\n",
    "    #     'hybrid_results': hybrid_results,\n",
    "    #     'unet_history': unet_history,\n",
    "    #     'hybrid_history': hybrid_history\n",
    "    # }\n",
    "    \n",
    "    # with open('./model_outputs/results_summary.json', 'w') as f:\n",
    "    #     json.dump(results_summary, f, indent=2)\n",
    "    \n",
    "    print(\"\\nPipeline tamamlandı!\")\n",
    "    print(\"Sonuçlar ./model_outputs/ klasörüne kaydedildi.\")\n",
    "\n",
    "# Pipeline'ı çalıştırmak için:\n",
    "# main_training_pipeline()\n",
    "\n",
    "print(\"Ana eğitim pipeline'ı hazır. main_training_pipeline() fonksiyonunu çağırarak başlatabilirsiniz.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonuç ve İstatistikler\n",
    "\n",
    "Bu notebook, beyin inmesi lezyon segmentasyonu projesi için kapsamlı bir eğitim ve değerlendirme pipeline'ı sağlar.\n",
    "\n",
    "### Beklenen Sonuçlar:\n",
    "\n",
    "1. **Standart U-Net**:\n",
    "   - Dice Score: ~0.75-0.85\n",
    "   - IoU Score: ~0.60-0.75\n",
    "   - Hızlı eğitim ve çıkarım\n",
    "\n",
    "2. **Hibrit Topolojik U-Net**:\n",
    "   - Dice Score: ~0.80-0.90 (beklenen iyileştirme)\n",
    "   - IoU Score: ~0.65-0.80\n",
    "   - Daha iyi şekil farkındalığı\n",
    "   - Küçük lezyonlarda iyileştirilmiş performans\n",
    "\n",
    "### Topolojik Yaklaşımın Avantajları:\n",
    "\n",
    "- **Şekil Tutarlılığı**: Lezyon sınırlarının daha doğru tespiti\n",
    "- **Küçük Yapı Tespiti**: Düşük kontrast alanlarında iyileştirilmiş hassasiyet\n",
    "- **Anatomik Tutarlılık**: Topolojik kısıtlamalarla daha gerçekçi segmentasyon\n",
    "- **Gürültü Direnci**: Görüntü kalitesi düşük olduğunda daha sağlam performans\n",
    "\n",
    "### Gelecek Çalışmalar:\n",
    "\n",
    "1. **Daha Sofistike Topolojik Özellikler**: İleri persistent homology teknikleri\n",
    "2. **Multi-scale Analiz**: Farklı ölçeklerde topolojik özellik çıkarımı\n",
    "3. **3D Genişletme**: Volumetrik CT verileri için 3D topolojik analiz\n",
    "4. **Real-time Uygulama**: Klinik ortamda kullanım için optimizasyon\n",
    "\n",
    "Bu çalışma, topolojik derin öğrenmenin tıbbi görüntü segmentasyonundaki potansiyelini göstermektedir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
