{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net ve Hibrit Model Mimarileri\n",
    "\n",
    "Bu notebook, standart U-Net ve topolojik özelliklerle desteklenmiş hibrit segmentasyon modellerini içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Önceki notebook'lardan import (gerçek uygulamada ayrı modül olacak)\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Kullanılan device: {device}\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standart U-Net Mimarisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes=1, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# Standart U-Net modelini test et\n",
    "model = UNet(n_channels=1, n_classes=1)\n",
    "print(f\"U-Net parametrelerinin sayısı: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Test girişi\n",
    "test_input = torch.randn(1, 1, 512, 512)\n",
    "with torch.no_grad():\n",
    "    output = model(test_input)\n",
    "    print(f\"Giriş boyutu: {test_input.shape}\")\n",
    "    print(f\"Çıkış boyutu: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topolojik Destekli Hibrit U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopologyAwareUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Topolojik özelliklerle desteklenmiş U-Net mimarisi\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=1, n_classes=1, bilinear=False, topo_feature_dim=32):\n",
    "        super(TopologyAwareUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.topo_feature_dim = topo_feature_dim\n",
    "        \n",
    "        # Standart U-Net encoder\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        \n",
    "        # Topolojik özellik işleme (basitleştirilmiş versiyon)\n",
    "        self.topo_processor = nn.Sequential(\n",
    "            nn.Linear(19, 64),  # 19: topolojik özellik boyutu\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, topo_feature_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Topolojik özellikler için spatial projection\n",
    "        self.topo_spatial = nn.Sequential(\n",
    "            nn.Linear(topo_feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 16 * 16),  # 16x16 spatial map\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Özellik birleştirme için bottleneck\n",
    "        bottleneck_channels = 1024 // factor + 1  # +1 for topological map\n",
    "        self.feature_fusion = DoubleConv(bottleneck_channels, 1024 // factor)\n",
    "        \n",
    "        # U-Net decoder (modifiye edilmiş)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "        \n",
    "        # Attention mechanism için\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def extract_simple_topo_features(self, x):\n",
    "        \"\"\"\n",
    "        Basitleştirilmiş topolojik özellik çıkarımı\n",
    "        (Gerçek uygulamada TopologicalLayer kullanılacak)\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        features = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            img = x[i, 0].cpu().numpy()\n",
    "            \n",
    "            # Basit topolojik özellikler\n",
    "            # Gerçek uygulamada persistent homology kullanılacak\n",
    "            \n",
    "            # Bağlantısız bileşen sayısı (threshold'lu)\n",
    "            binary = (img > 0.5).astype(np.uint8)\n",
    "            num_labels, labels = cv2.connectedComponents(binary)\n",
    "            \n",
    "            # Basit istatistikler\n",
    "            mean_val = img.mean()\n",
    "            std_val = img.std()\n",
    "            min_val = img.min()\n",
    "            max_val = img.max()\n",
    "            \n",
    "            # Gradient based features\n",
    "            grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
    "            \n",
    "            feature_vec = [\n",
    "                num_labels,  # Connected components\n",
    "                mean_val, std_val, min_val, max_val,  # Basic stats\n",
    "                grad_mag.mean(), grad_mag.std(),  # Gradient stats\n",
    "                *np.histogram(img.flatten(), bins=10)[0] / img.size,  # Histogram (10 bins)\n",
    "                (img > img.mean()).sum() / img.size,  # Above mean ratio\n",
    "                np.median(img)  # Median\n",
    "            ]\n",
    "            \n",
    "            # Pad to 19 features\n",
    "            while len(feature_vec) < 19:\n",
    "                feature_vec.append(0.0)\n",
    "            \n",
    "            features.append(feature_vec[:19])\n",
    "        \n",
    "        return torch.FloatTensor(features).to(x.device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Standart U-Net encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)  # Bottleneck\n",
    "        \n",
    "        # Topolojik özellikler çıkar\n",
    "        topo_features = self.extract_simple_topo_features(x)\n",
    "        \n",
    "        # Topolojik özellikleri işle\n",
    "        topo_processed = self.topo_processor(topo_features)\n",
    "        \n",
    "        # Spatial map'e çevir\n",
    "        topo_spatial = self.topo_spatial(topo_processed)\n",
    "        topo_map = topo_spatial.view(-1, 1, 16, 16)\n",
    "        \n",
    "        # Bottleneck boyutuna upsample\n",
    "        topo_map_upsampled = F.interpolate(\n",
    "            topo_map, \n",
    "            size=(x5.shape[2], x5.shape[3]), \n",
    "            mode='bilinear', \n",
    "            align_corners=True\n",
    "        )\n",
    "        \n",
    "        # Özellikleri birleştir\n",
    "        fused_features = torch.cat([x5, topo_map_upsampled], dim=1)\n",
    "        fused_features = self.feature_fusion(fused_features)\n",
    "        \n",
    "        # U-Net decoder\n",
    "        x = self.up1(fused_features, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention(x)\n",
    "        x = x * attention_weights\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# Hibrit modeli test et\n",
    "hybrid_model = TopologyAwareUNet(n_channels=1, n_classes=1, topo_feature_dim=32)\n",
    "print(f\"Hibrit U-Net parametrelerinin sayısı: {sum(p.numel() for p in hybrid_model.parameters()):,}\")\n",
    "\n",
    "# Test girişi\n",
    "with torch.no_grad():\n",
    "    hybrid_output = hybrid_model(test_input)\n",
    "    print(f\"Hibrit model çıkış boyutu: {hybrid_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Fonksiyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dice Loss - segmentasyon için yaygın kullanılan loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Sigmoid uygula\n",
    "        pred = torch.sigmoid(pred)\n",
    "        \n",
    "        # Flatten\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        # Dice coefficient\n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    BCE + Dice Loss kombinasyonu\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dice_weight=0.5, bce_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        bce = self.bce_loss(pred, target)\n",
    "        \n",
    "        return self.dice_weight * dice + self.bce_weight * bce\n",
    "\n",
    "\n",
    "class TopologicalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Topolojik tutarlılık için ek loss\n",
    "    Betti sayıları arasındaki farkı minimize eder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weight=0.1):\n",
    "        super(TopologicalLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "    \n",
    "    def compute_betti_0(self, mask):\n",
    "        \"\"\"\n",
    "        0. Betti sayısını (bağlantısız bileşen sayısını) hesapla\n",
    "        \"\"\"\n",
    "        batch_size = mask.shape[0]\n",
    "        betti_0_counts = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Binary mask\n",
    "            binary_mask = (mask[i, 0] > 0.5).cpu().numpy().astype(np.uint8)\n",
    "            \n",
    "            # Connected components\n",
    "            num_labels, _ = cv2.connectedComponents(binary_mask)\n",
    "            betti_0_counts.append(num_labels - 1)  # -1 for background\n",
    "        \n",
    "        return torch.FloatTensor(betti_0_counts).to(mask.device)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Sigmoid uygula\n",
    "        pred_prob = torch.sigmoid(pred)\n",
    "        \n",
    "        # Betti sayılarını hesapla\n",
    "        pred_betti = self.compute_betti_0(pred_prob)\n",
    "        target_betti = self.compute_betti_0(target)\n",
    "        \n",
    "        # L1 loss\n",
    "        topo_loss = torch.mean(torch.abs(pred_betti - target_betti))\n",
    "        \n",
    "        return self.weight * topo_loss\n",
    "\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Hibrit model için kombine loss: Segmentasyon + Topolojik\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dice_weight=0.4, bce_weight=0.4, topo_weight=0.2):\n",
    "        super(HybridLoss, self).__init__()\n",
    "        self.segmentation_loss = CombinedLoss(dice_weight/(dice_weight+bce_weight), \n",
    "                                            bce_weight/(dice_weight+bce_weight))\n",
    "        self.topological_loss = TopologicalLoss()\n",
    "        self.seg_weight = dice_weight + bce_weight\n",
    "        self.topo_weight = topo_weight\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        seg_loss = self.segmentation_loss(pred, target)\n",
    "        topo_loss = self.topological_loss(pred, target)\n",
    "        \n",
    "        total_loss = self.seg_weight * seg_loss + self.topo_weight * topo_loss\n",
    "        \n",
    "        return total_loss, seg_loss, topo_loss\n",
    "\n",
    "# Test loss fonksiyonları\n",
    "print(\"Loss fonksiyonları test ediliyor...\")\n",
    "\n",
    "# Dummy data\n",
    "pred = torch.randn(2, 1, 64, 64)\n",
    "target = torch.randint(0, 2, (2, 1, 64, 64)).float()\n",
    "\n",
    "# Test losses\n",
    "dice_loss = DiceLoss()\n",
    "combined_loss = CombinedLoss()\n",
    "hybrid_loss = HybridLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    dice_val = dice_loss(pred, target)\n",
    "    combined_val = combined_loss(pred, target)\n",
    "    hybrid_val, seg_val, topo_val = hybrid_loss(pred, target)\n",
    "    \n",
    "    print(f\"Dice Loss: {dice_val.item():.4f}\")\n",
    "    print(f\"Combined Loss: {combined_val.item():.4f}\")\n",
    "    print(f\"Hybrid Loss: {hybrid_val.item():.4f} (Seg: {seg_val.item():.4f}, Topo: {topo_val.item():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Değerlendirme Metrikleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Segmentasyon performans metrikleri\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=0.5):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def dice_score(self, pred, target, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Dice skorunu hesapla\n",
    "        \"\"\"\n",
    "        pred = (torch.sigmoid(pred) > self.threshold).float()\n",
    "        \n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "        \n",
    "        return dice.item()\n",
    "    \n",
    "    def iou_score(self, pred, target, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Intersection over Union skorunu hesapla\n",
    "        \"\"\"\n",
    "        pred = (torch.sigmoid(pred) > self.threshold).float()\n",
    "        \n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        intersection = (pred * target).sum()\n",
    "        union = pred.sum() + target.sum() - intersection\n",
    "        \n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        \n",
    "        return iou.item()\n",
    "    \n",
    "    def precision_recall(self, pred, target):\n",
    "        \"\"\"\n",
    "        Precision ve Recall hesapla\n",
    "        \"\"\"\n",
    "        pred = (torch.sigmoid(pred) > self.threshold).float()\n",
    "        \n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        tp = (pred * target).sum()\n",
    "        fp = (pred * (1 - target)).sum()\n",
    "        fn = ((1 - pred) * target).sum()\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        recall = tp / (tp + fn + 1e-6)\n",
    "        \n",
    "        return precision.item(), recall.item()\n",
    "    \n",
    "    def hausdorff_distance(self, pred, target):\n",
    "        \"\"\"\n",
    "        Basitleştirilmiş Hausdorff mesafesi\n",
    "        \"\"\"\n",
    "        pred = (torch.sigmoid(pred) > self.threshold).float()\n",
    "        \n",
    "        batch_size = pred.shape[0]\n",
    "        distances = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            pred_np = pred[i, 0].cpu().numpy().astype(np.uint8)\n",
    "            target_np = target[i, 0].cpu().numpy().astype(np.uint8)\n",
    "            \n",
    "            # Contour'ları bul\n",
    "            pred_contours, _ = cv2.findContours(pred_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            target_contours, _ = cv2.findContours(target_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            if len(pred_contours) == 0 or len(target_contours) == 0:\n",
    "                distances.append(float('inf'))\n",
    "                continue\n",
    "            \n",
    "            # Basit mesafe hesabı (gerçek Hausdorff'un basitleştirilmiş versiyonu)\n",
    "            pred_points = np.vstack(pred_contours[0])\n",
    "            target_points = np.vstack(target_contours[0])\n",
    "            \n",
    "            # Ortalama mesafe\n",
    "            from scipy.spatial.distance import cdist\n",
    "            dist_matrix = cdist(pred_points[:, 0], target_points[:, 0])\n",
    "            distances.append(np.mean(dist_matrix.min(axis=1)))\n",
    "        \n",
    "        return np.mean(distances)\n",
    "    \n",
    "    def compute_all_metrics(self, pred, target):\n",
    "        \"\"\"\n",
    "        Tüm metrikleri hesapla\n",
    "        \"\"\"\n",
    "        dice = self.dice_score(pred, target)\n",
    "        iou = self.iou_score(pred, target)\n",
    "        precision, recall = self.precision_recall(pred, target)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        \n",
    "        try:\n",
    "            hausdorff = self.hausdorff_distance(pred, target)\n",
    "        except:\n",
    "            hausdorff = float('inf')\n",
    "        \n",
    "        return {\n",
    "            'dice': dice,\n",
    "            'iou': iou,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'hausdorff': hausdorff\n",
    "        }\n",
    "\n",
    "# Test metrikleri\n",
    "print(\"Metrikler test ediliyor...\")\n",
    "metrics = SegmentationMetrics()\n",
    "\n",
    "# Dummy data ile test\n",
    "pred_test = torch.randn(1, 1, 64, 64)\n",
    "target_test = torch.randint(0, 2, (1, 1, 64, 64)).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_metrics = metrics.compute_all_metrics(pred_test, target_test)\n",
    "    print(\"Test metrikleri:\")\n",
    "    for metric_name, value in all_metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Karşılaştırma Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(unet_model, hybrid_model, test_loader, device, num_samples=5):\n",
    "    \"\"\"\n",
    "    İki modeli karşılaştır ve sonuçları görselleştir\n",
    "    \"\"\"\n",
    "    unet_model.eval()\n",
    "    hybrid_model.eval()\n",
    "    metrics = SegmentationMetrics()\n",
    "    \n",
    "    unet_metrics = []\n",
    "    hybrid_metrics = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Model tahminleri\n",
    "            unet_pred = unet_model(images)\n",
    "            hybrid_pred = hybrid_model(images)\n",
    "            \n",
    "            # Metrikleri hesapla\n",
    "            unet_metric = metrics.compute_all_metrics(unet_pred, masks)\n",
    "            hybrid_metric = metrics.compute_all_metrics(hybrid_pred, masks)\n",
    "            \n",
    "            unet_metrics.append(unet_metric)\n",
    "            hybrid_metrics.append(hybrid_metric)\n",
    "            \n",
    "            # İlk örneği görselleştir\n",
    "            if i == 0:\n",
    "                # Görselleştirme\n",
    "                fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "                \n",
    "                # İlk satır: Orijinal, Ground Truth, U-Net, Hibrit\n",
    "                axes[0, 0].imshow(images[0, 0].cpu().numpy(), cmap='gray')\n",
    "                axes[0, 0].set_title('Orijinal Görüntü')\n",
    "                axes[0, 0].axis('off')\n",
    "                \n",
    "                axes[0, 1].imshow(masks[0, 0].cpu().numpy(), cmap='hot')\n",
    "                axes[0, 1].set_title('Ground Truth')\n",
    "                axes[0, 1].axis('off')\n",
    "                \n",
    "                unet_prob = torch.sigmoid(unet_pred[0, 0]).cpu().numpy()\n",
    "                axes[0, 2].imshow(unet_prob, cmap='hot')\n",
    "                axes[0, 2].set_title(f'U-Net (Dice: {unet_metric[\"dice\"]:.3f})')\n",
    "                axes[0, 2].axis('off')\n",
    "                \n",
    "                hybrid_prob = torch.sigmoid(hybrid_pred[0, 0]).cpu().numpy()\n",
    "                axes[0, 3].imshow(hybrid_prob, cmap='hot')\n",
    "                axes[0, 3].set_title(f'Hibrit (Dice: {hybrid_metric[\"dice\"]:.3f})')\n",
    "                axes[0, 3].axis('off')\n",
    "                \n",
    "                # İkinci satır: Binary tahminler\n",
    "                axes[1, 0].imshow(images[0, 0].cpu().numpy(), cmap='gray')\n",
    "                axes[1, 0].set_title('Orijinal')\n",
    "                axes[1, 0].axis('off')\n",
    "                \n",
    "                axes[1, 1].imshow(masks[0, 0].cpu().numpy(), cmap='gray')\n",
    "                axes[1, 1].set_title('Ground Truth')\n",
    "                axes[1, 1].axis('off')\n",
    "                \n",
    "                unet_binary = (unet_prob > 0.5).astype(np.float32)\n",
    "                axes[1, 2].imshow(unet_binary, cmap='gray')\n",
    "                axes[1, 2].set_title(f'U-Net Binary (IoU: {unet_metric[\"iou\"]:.3f})')\n",
    "                axes[1, 2].axis('off')\n",
    "                \n",
    "                hybrid_binary = (hybrid_prob > 0.5).astype(np.float32)\n",
    "                axes[1, 3].imshow(hybrid_binary, cmap='gray')\n",
    "                axes[1, 3].set_title(f'Hibrit Binary (IoU: {hybrid_metric[\"iou\"]:.3f})')\n",
    "                axes[1, 3].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    # Ortalama metrikleri hesapla\n",
    "    avg_unet_metrics = {}\n",
    "    avg_hybrid_metrics = {}\n",
    "    \n",
    "    for key in unet_metrics[0].keys():\n",
    "        avg_unet_metrics[key] = np.mean([m[key] for m in unet_metrics])\n",
    "        avg_hybrid_metrics[key] = np.mean([m[key] for m in hybrid_metrics])\n",
    "    \n",
    "    # Metrik karşılaştırması\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    metrics_names = list(avg_unet_metrics.keys())\n",
    "    metrics_names = [m for m in metrics_names if m != 'hausdorff']  # Hausdorff görselleştirmeden çıkar\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    unet_values = [avg_unet_metrics[m] for m in metrics_names]\n",
    "    hybrid_values = [avg_hybrid_metrics[m] for m in metrics_names]\n",
    "    \n",
    "    ax.bar(x - width/2, unet_values, width, label='Standart U-Net', alpha=0.7)\n",
    "    ax.bar(x + width/2, hybrid_values, width, label='Hibrit U-Net', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Metrikler')\n",
    "    ax.set_ylabel('Skor')\n",
    "    ax.set_title('Model Performans Karşılaştırması')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics_names)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nOrtalama Performans Metrikleri:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Metrik':<12} {'U-Net':<10} {'Hibrit':<10} {'İyileştirme':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for key in metrics_names:\n",
    "        unet_val = avg_unet_metrics[key]\n",
    "        hybrid_val = avg_hybrid_metrics[key]\n",
    "        improvement = ((hybrid_val - unet_val) / unet_val) * 100\n",
    "        \n",
    "        print(f\"{key:<12} {unet_val:<10.4f} {hybrid_val:<10.4f} {improvement:<12.2f}%\")\n",
    "    \n",
    "    return avg_unet_metrics, avg_hybrid_metrics\n",
    "\n",
    "print(\"Model karşılaştırma fonksiyonu hazır.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonraki Adımlar\n",
    "\n",
    "Bu notebook'ta geliştirdiğimiz bileşenler:\n",
    "\n",
    "1. **Standart U-Net mimarisi**\n",
    "2. **Topolojik destekli hibrit U-Net**\n",
    "3. **Özelleşmiş loss fonksiyonları** (Dice, BCE, Topological)\n",
    "4. **Kapsamlı değerlendirme metrikleri**\n",
    "5. **Model karşılaştırma araçları**\n",
    "\n",
    "Sonraki notebook'ta bu modelleri eğiteceğiz ve detaylı performans analizini yapacağız."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}