{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Yükleme ve Ön İşleme\n",
    "\n",
    "Bu notebook, beyin inmesi CT görüntülerinin yüklenmesi ve ön işlenmesi için gerekli kodları içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Görselleştirme ayarları\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Kütüphaneler başarıyla yüklendi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Seti Sınıfı (Dataset Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainStrokeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Beyin inmesi CT görüntüleri için PyTorch Dataset sınıfı\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir, mask_dir, transform=None, augment=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): CT görüntülerinin bulunduğu klasör\n",
    "            mask_dir (str): Segmentasyon maskelerinin bulunduğu klasör\n",
    "            transform (callable, optional): Görüntülere uygulanacak dönüşümler\n",
    "            augment (bool): Veri artırma uygulanıp uygulanmayacağı\n",
    "        \"\"\"\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Görüntü dosyalarını listele\n",
    "        self.image_files = sorted(list(self.image_dir.glob('*.png')) + \n",
    "                                 list(self.image_dir.glob('*.jpg')) +\n",
    "                                 list(self.image_dir.glob('*.nii.gz')))\n",
    "        \n",
    "        print(f\"Toplam {len(self.image_files)} görüntü bulundu.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Görüntü dosyasını yükle\n",
    "        img_path = self.image_files[idx]\n",
    "        \n",
    "        if img_path.suffix == '.gz':  # NIfTI dosyası\n",
    "            img = nib.load(img_path).get_fdata()\n",
    "            if img.ndim == 3:  # 3D ise orta slice'ı al\n",
    "                img = img[:, :, img.shape[2]//2]\n",
    "        else:  # PNG/JPG dosyası\n",
    "            img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Mask dosyasını yükle\n",
    "        mask_path = self.mask_dir / (img_path.stem + '_mask.png')\n",
    "        if mask_path.exists():\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            mask = np.zeros_like(img)\n",
    "        \n",
    "        # Normalizasyon\n",
    "        img = self.normalize_ct_image(img)\n",
    "        mask = (mask > 127).astype(np.float32)  # Binary mask\n",
    "        \n",
    "        # Tensor'e çevir\n",
    "        img = torch.from_numpy(img).unsqueeze(0).float()  # (1, H, W)\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).float()  # (1, H, W)\n",
    "        \n",
    "        # Transform uygula\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, mask\n",
    "    \n",
    "    def normalize_ct_image(self, img):\n",
    "        \"\"\"\n",
    "        CT görüntüsünü Hounsfield Unit (HU) değerlerine göre normalize et\n",
    "        \"\"\"\n",
    "        # CT değerlerini -1000 (hava) ile 400 (kemik) arasında kırp\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        \n",
    "        # 0-1 aralığına normalize et\n",
    "        img = (img + 1000) / 1400\n",
    "        \n",
    "        return img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Artırma (Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_transforms():\n",
    "    \"\"\"\n",
    "    Eğitim için veri artırma dönüşümleri\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # -1 ile 1 arasına normalize et\n",
    "    ])\n",
    "\n",
    "def get_validation_transforms():\n",
    "    \"\"\"\n",
    "    Doğrulama için basit normalizasyon\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Seti Yükleme ve Bölme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yolları\n",
    "dataset_root = Path('./dataset')\n",
    "image_dir = dataset_root / 'images'\n",
    "mask_dir = dataset_root / 'masks'\n",
    "\n",
    "# Test için örnek veri oluştur (gerçek veri yoksa)\n",
    "def create_sample_data():\n",
    "    \"\"\"\n",
    "    Test için örnek veri oluştur\n",
    "    \"\"\"\n",
    "    image_dir.mkdir(exist_ok=True)\n",
    "    mask_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for i in range(5):\n",
    "        # Örnek CT görüntüsü (512x512)\n",
    "        img = np.random.randint(0, 255, (512, 512), dtype=np.uint8)\n",
    "        \n",
    "        # Örnek lezyon (dairesel)\n",
    "        mask = np.zeros((512, 512), dtype=np.uint8)\n",
    "        center = (256 + np.random.randint(-100, 100), 256 + np.random.randint(-100, 100))\n",
    "        radius = np.random.randint(20, 80)\n",
    "        cv2.circle(mask, center, radius, 255, -1)\n",
    "        \n",
    "        # Dosyalara kaydet\n",
    "        cv2.imwrite(str(image_dir / f'sample_{i:03d}.png'), img)\n",
    "        cv2.imwrite(str(mask_dir / f'sample_{i:03d}_mask.png'), mask)\n",
    "    \n",
    "    print(\"Örnek veri oluşturuldu.\")\n",
    "\n",
    "# Gerçek veri yoksa örnek veri oluştur\n",
    "if not image_dir.exists() or len(list(image_dir.glob('*'))) == 0:\n",
    "    create_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset'leri oluştur\n",
    "train_dataset = BrainStrokeDataset(\n",
    "    image_dir=image_dir,\n",
    "    mask_dir=mask_dir,\n",
    "    transform=get_augmentation_transforms(),\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = BrainStrokeDataset(\n",
    "    image_dir=image_dir,\n",
    "    mask_dir=mask_dir,\n",
    "    transform=get_validation_transforms(),\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# DataLoader'ları oluştur\n",
    "batch_size = 4\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Eğitim dataset boyutu: {len(train_dataset)}\")\n",
    "print(f\"Doğrulama dataset boyutu: {len(val_dataset)}\")\n",
    "print(f\"Batch boyutu: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(dataloader, num_samples=4):\n",
    "    \"\"\"\n",
    "    Bir batch'ten örnek görüntüleri görselleştir\n",
    "    \"\"\"\n",
    "    dataiter = iter(dataloader)\n",
    "    images, masks = next(dataiter)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 8))\n",
    "    \n",
    "    for i in range(min(num_samples, images.shape[0])):\n",
    "        # Görüntüyü göster\n",
    "        img = images[i, 0].cpu().numpy()\n",
    "        axes[0, i].imshow(img, cmap='gray')\n",
    "        axes[0, i].set_title(f'CT Görüntüsü {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Maski göster\n",
    "        mask = masks[i, 0].cpu().numpy()\n",
    "        axes[1, i].imshow(mask, cmap='hot')\n",
    "        axes[1, i].set_title(f'Segmentasyon Maskesi {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Örnek batch görselleştir\n",
    "visualize_batch(train_loader, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri İstatistikleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_statistics(dataset):\n",
    "    \"\"\"\n",
    "    Dataset istatistiklerini analiz et\n",
    "    \"\"\"\n",
    "    pixel_values = []\n",
    "    mask_ratios = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        img, mask = dataset[i]\n",
    "        \n",
    "        # Piksel değer istatistikleri\n",
    "        pixel_values.extend(img.flatten().numpy())\n",
    "        \n",
    "        # Lezyon oranı\n",
    "        mask_ratio = mask.sum() / mask.numel()\n",
    "        mask_ratios.append(mask_ratio.item())\n",
    "    \n",
    "    # İstatistikleri göster\n",
    "    pixel_values = np.array(pixel_values)\n",
    "    mask_ratios = np.array(mask_ratios)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Piksel değer dağılımı\n",
    "    axes[0].hist(pixel_values, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_title('Piksel Değer Dağılımı')\n",
    "    axes[0].set_xlabel('Piksel Değeri')\n",
    "    axes[0].set_ylabel('Frekans')\n",
    "    \n",
    "    # Lezyon oranı dağılımı\n",
    "    axes[1].hist(mask_ratios, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axes[1].set_title('Lezyon Oranı Dağılımı')\n",
    "    axes[1].set_xlabel('Lezyon Oranı')\n",
    "    axes[1].set_ylabel('Frekans')\n",
    "    \n",
    "    # Box plot\n",
    "    axes[2].boxplot([mask_ratios], labels=['Lezyon Oranı'])\n",
    "    axes[2].set_title('Lezyon Oranı İstatistikleri')\n",
    "    axes[2].set_ylabel('Oran')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Ortalama piksel değeri: {pixel_values.mean():.4f}\")\n",
    "    print(f\"Piksel değeri std: {pixel_values.std():.4f}\")\n",
    "    print(f\"Ortalama lezyon oranı: {mask_ratios.mean():.4f}\")\n",
    "    print(f\"Lezyon oranı std: {mask_ratios.std():.4f}\")\n",
    "\n",
    "# Dataset istatistiklerini analiz et\n",
    "analyze_dataset_statistics(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonraki Adımlar\n",
    "\n",
    "Bu notebook'ta veri yükleme ve ön işleme kodlarını geliştirdik. Sonraki notebook'larda:\n",
    "\n",
    "1. **Topolojik özellik çıkarımı** (GUDHI/gtda kullanarak)\n",
    "2. **U-Net ve hibrit model mimarileri**\n",
    "3. **Model eğitimi ve değerlendirmesi**\n",
    "4. **Sonuçların karşılaştırmalı analizi**\n",
    "\n",
    "konularını ele alacağız."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}